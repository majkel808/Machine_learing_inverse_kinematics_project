{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309adf2d-1185-45b2-9640-5321acf40263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From local\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv(\"collected_data_180_step_4.csv\")\n",
    "    \n",
    "print(\"From local\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Train test split\n",
    "X_train_df, X_test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train values\n",
    "y1_train = np.array(X_train_df[\"Theta1\"])\n",
    "y2_train = np.array(X_train_df[\"Theta2\"])\n",
    "y3_train = np.array(X_train_df[\"Theta3\"])\n",
    "\n",
    "# Test values\n",
    "y1_test = np.array(X_test_df[\"Theta1\"])\n",
    "y2_test = np.array(X_test_df[\"Theta2\"])\n",
    "y3_test = np.array(X_test_df[\"Theta3\"])\n",
    "\n",
    "# Remove the target values from the dataset\n",
    "X_train_df = X_train_df.drop([\"Theta1\", \"Theta2\", \"Theta3\"], axis=1)\n",
    "X_test_df = X_test_df.drop([\"Theta1\", \"Theta2\", \"Theta3\"], axis=1)\n",
    "\n",
    "# Normalizing the dataset\n",
    "X_train_norm = (X_train_df - X_train_df.mean()) / X_train_df.std()\n",
    "X_test_norm = (X_test_df - X_test_df.mean()) / X_test_df.std()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = X_train_norm.values\n",
    "X_valid = X_test_norm.values\n",
    "\n",
    "y1_train = y1_train.reshape(-1, 1) # Reshape y1_train to match X_train\n",
    "y2_train = y2_train.reshape(-1, 1) # Reshape y2_train to match X_train\n",
    "y3_train = y3_train.reshape(-1, 1) # Reshape y3_train to match X_train\n",
    "\n",
    "y1_test = y1_test.reshape(-1, 1) # Reshape y1_train to match X_train\n",
    "y2_test = y2_test.reshape(-1, 1) # Reshape y2_train to match X_train\n",
    "y3_test = y3_test.reshape(-1, 1) # Reshape y2_train to match X_train\n",
    "\n",
    "y_train = (y1_train, y2_train, y3_train)\n",
    "y_valid = (y1_test, y2_test, y3_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedfc1bc-afb7-4fb8-9f39-40f51c398161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_1 =  X_train_df.shape\n",
    "index_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99d6b55-23d7-4b99-acf2-eb875e19147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  4.],\n",
       "        [136.],\n",
       "        [ 60.],\n",
       "        ...,\n",
       "        [148.],\n",
       "        [  0.],\n",
       "        [ 28.]]),\n",
       " array([[108.],\n",
       "        [132.],\n",
       "        [144.],\n",
       "        ...,\n",
       "        [168.],\n",
       "        [ 76.],\n",
       "        [144.]]),\n",
       " array([[176.],\n",
       "        [112.],\n",
       "        [  8.],\n",
       "        ...,\n",
       "        [ 20.],\n",
       "        [ 20.],\n",
       "        [  0.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f50be5-1df7-4c17-9c5a-3a2a3c2b6ee9",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">CREATING THE MODEL</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0527c160-ea13-4bbc-8343-774ee4fc445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_valid, y_valid, input_nodes, hidden_nodes, hidden_nodes_2, output_nodes, learning_rate, batch_size, epochs, dropout_rate):\n",
    "    \"\"\"\n",
    "    Train a neural network model for multi-output regression.\n",
    "\n",
    "    Args:\n",
    "    X_train (numpy.ndarray): Input features for training.\n",
    "    y_train (tuple of numpy.ndarray): Target labels for training.\n",
    "    X_valid (numpy.ndarray): Input features for validation.\n",
    "    y_valid (tuple of numpy.ndarray): Target labels for validation.\n",
    "    input_nodes (int): Number of nodes in the input layers of the neural network.\n",
    "    hidden_nodes (int): Number of nodes in the first hidden layer of the neural network.\n",
    "    hidden_nodes_2 (int): Number of nodes in the second hidden layer of the neural network.\n",
    "    output_nodes (tuple of int): Number of nodes in the output layers of the neural network.\n",
    "    learning_rate (float): Learning rate for the optimizer.\n",
    "    batch_size (int): Number of samples per batch during training.\n",
    "    epochs (int): Number of epochs for training.\n",
    "    dropout_rate (float): Dropout rate for regularization.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - nn_model (keras.Model): Trained neural network model.\n",
    "        - history (dict): Training history.\n",
    "    \"\"\"\n",
    "    # Unpack target labels\n",
    "    y1_train, y2_train, y3_train = y_train\n",
    "    y1_valid, y2_valid, y3_valid = y_valid\n",
    "\n",
    "    # Define input layer\n",
    "    input_layer = Input(shape=(input_nodes,))\n",
    "\n",
    "    # Define dense layers\n",
    "    dense_layer_1 = Dense(units=hidden_nodes, activation=\"relu\")(input_layer)\n",
    "    dropout_layer_1 = Dropout(dropout_rate)(dense_layer_1)  # Adding dropout after the first dense layer\n",
    "\n",
    "    \n",
    "    dense_layer_2 = Dense(units=hidden_nodes, activation=\"relu\")(dropout_layer_1)\n",
    "    dropout_layer_2 = Dropout(dropout_rate)(dense_layer_2)  # Adding dropout after the second dense layer\n",
    "\n",
    "    dense_layer_3 = Dense(units=hidden_nodes_2, activation=\"relu\")(dropout_layer_2)\n",
    "    \n",
    "    dense_layer_4 = Dense(units=hidden_nodes_2, activation=\"relu\")(dense_layer_3)\n",
    "    \n",
    "    # Define Y1 output\n",
    "    y1_output = Dense(units=1, activation=\"linear\", name=\"y1_output\")(dropout_layer_2)\n",
    "\n",
    "    # Define Y2 output\n",
    "    y2_output = Dense(units=1, activation=\"linear\", name=\"y2_output\")(dense_layer_3)\n",
    "\n",
    "    # Define Y3 output\n",
    "    y3_output = Dense(units=1, activation=\"linear\", name=\"y3_output\")(dense_layer_4)\n",
    "\n",
    "    # Define the model with the input layer and a list of outputs\n",
    "    model = Model(inputs=input_layer, outputs=[y1_output, y2_output, y3_output])\n",
    "\n",
    "    # Specify the optimizer\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss={'y1_output': 'mse', 'y2_output': 'mse', 'y3_output': 'mse'},\n",
    "                  metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError(),\n",
    "                           'y2_output': tf.keras.metrics.RootMeanSquaredError(),\n",
    "                           'y3_output': tf.keras.metrics.RootMeanSquaredError()})\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, {'y1_output': y1_train, 'y2_output': y2_train, 'y3_output': y3_train},\n",
    "                        validation_data=(X_valid, {'y1_output': y1_valid, 'y2_output': y2_valid, 'y3_output': y3_valid}),\n",
    "                        epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Show the difference in loss and RMSE with each epoch of training the model.\n",
    "\n",
    "    Args:\n",
    "       history : Keras History object that stores information about the trained model.\n",
    "\n",
    "    Returns:\n",
    "        Plot showing the loss and RMSE with each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(20, 24))\n",
    "\n",
    "    # Plot loss for y1\n",
    "    axs[0, 0].plot(history.history['loss'], label='loss (y1)')\n",
    "    axs[0, 0].plot(history.history['val_loss'], label='val_loss (y1)')\n",
    "    axs[0, 0].set_xlabel('Epoch')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].grid(True)\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Plot RMSE for y1\n",
    "    axs[0, 1].plot(history.history['y1_output_root_mean_squared_error'], label='RMSE (y1)')\n",
    "    axs[0, 1].plot(history.history['val_y1_output_root_mean_squared_error'], label='val_RMSE (y1)')\n",
    "    axs[0, 1].set_xlabel('Epoch')\n",
    "    axs[0, 1].set_ylabel('RMSE')\n",
    "    axs[0, 1].grid(True)\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Plot loss for y2\n",
    "    axs[1, 0].plot(history.history['loss'], label='loss (y2)')\n",
    "    axs[1, 0].plot(history.history['val_loss'], label='val_loss (y2)')\n",
    "    axs[1, 0].set_xlabel('Epoch')\n",
    "    axs[1, 0].set_ylabel('Loss')\n",
    "    axs[1, 0].grid(True)\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Plot RMSE for y2\n",
    "    axs[1, 1].plot(history.history['y2_output_root_mean_squared_error'], label='RMSE (y2)')\n",
    "    axs[1, 1].plot(history.history['val_y2_output_root_mean_squared_error'], label='val_RMSE (y2)')\n",
    "    axs[1, 1].set_xlabel('Epoch')\n",
    "    axs[1, 1].set_ylabel('RMSE')\n",
    "    axs[1, 1].grid(True)\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    # Plot loss for y3\n",
    "    axs[2, 0].plot(history.history['loss'], label='loss (y3)')\n",
    "    axs[2, 0].plot(history.history['val_loss'], label='val_loss (y3)')\n",
    "    axs[2, 0].set_xlabel('Epoch')\n",
    "    axs[2, 0].set_ylabel('Loss')\n",
    "    axs[2, 0].grid(True)\n",
    "    axs[2, 0].legend()\n",
    "\n",
    "    # Plot RMSE for y3\n",
    "    axs[2, 1].plot(history.history['y3_output_root_mean_squared_error'], label='RMSE (y3)')\n",
    "    axs[2, 1].plot(history.history['val_y3_output_root_mean_squared_error'], label='val_RMSE (y3)')\n",
    "    axs[2, 1].set_xlabel('Epoch')\n",
    "    axs[2, 1].set_ylabel('RMSE')\n",
    "    axs[2, 1].grid(True)\n",
    "    axs[2, 1].legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8bd568-c21d-4c1a-855a-dddd39a41e95",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">PARAMETERS OF THE MODEL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98885d6e-ced3-4303-8137-1fe74d4c0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = len(X_train[1])\n",
    "output_nodes = 1\n",
    "epochs = 100 #200/400 było git\n",
    "hidden_nodes = 128  #60 było git\n",
    "hidden_nodes_2 = 64  #64 było git\n",
    "dropout_rate = 0.25  #0.25 było git\n",
    "batch_size = 200\n",
    "learining_rate = 0.001 #0.001 było git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d5b4f-1596-4e06-a0cd-3971f3cb8648",
   "metadata": {},
   "source": [
    "<h2 style=\"font-size: 20px;\">TESTETING THE MODEL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df666d5b-bfe4-4fd8-b3cf-9bcfa41cd9f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[18], line 1\u001b[0m\n    model, history = train_model(X_train, y_train, X_valid, y_valid, input_nodes, hidden_nodes, hidden_nodes_2, output_nodes, learining_rate, batch_size, epochs, dropout_rate)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[15], line 66\u001b[0m in \u001b[0;35mtrain_model\u001b[0m\n    history = model.fit(X_train, {'y1_output': y1_train, 'y2_output': y2_train, 'y3_output': y3_train},\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m in \u001b[0;35merror_handler\u001b[0m\n    return fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m in \u001b[0;35mfit\u001b[0m\n    tmp_logs = self.train_function(iterator)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m in \u001b[0;35merror_handler\u001b[0m\n    return fn(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m in \u001b[0;35m__call__\u001b[0m\n    result = self._call(*args, **kwds)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m in \u001b[0;35m_call\u001b[0m\n    return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m in \u001b[0;35m__call__\u001b[0m\n    return concrete_function._call_flat(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m in \u001b[0;35m_call_flat\u001b[0m\n    return self._build_call_outputs(self._inference_function(*args))\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m in \u001b[0;35m__call__\u001b[0m\n    outputs = self._bound_context.call_function(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m in \u001b[0;35mcall_function\u001b[0m\n    outputs = execute.execute(\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[1;36m in \u001b[1;35mquick_execute\u001b[1;36m\n\u001b[1;33m    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\u001b[1;36m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(X_train, y_train, X_valid, y_valid, input_nodes, hidden_nodes, hidden_nodes_2, output_nodes, learining_rate, batch_size, epochs, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "872affbe-4330-43ee-9682-26a8a6aad26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/570 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.95128227e-01, -8.16416779e-01, -9.07050459e-01],\n",
       "       [ 2.69528669e+00, -2.38788082e-01, -1.14016130e+00],\n",
       "       [-2.33704529e-01, -1.99668644e+00,  2.56798540e-01],\n",
       "       ...,\n",
       "       [-6.07289688e-02,  2.73701892e-01, -7.14374993e-01],\n",
       "       [-6.45457975e-01, -1.22421086e-03, -1.68819738e+00],\n",
       "       [-9.09219250e-02,  1.29539676e+00,  1.02117795e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_history(history)\n",
    "\n",
    "Y1_pred , Y2_pred, Y3_pred = model.predict(X_valid)\n",
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a0f9b8-42d5-4b51-b1bd-98e2c712303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y1_test, Y1_pred)\n",
    "combined_array1 = np.column_stack((y1_test, Y1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48788477-5c39-4cd9-a830-cb413456a5f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_array1' is not defined",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\n\u001b[1;33m    combined_array1.shape()\u001b[1;36m\n",
      "\u001b[1;31mNameError\u001b[0m\u001b[1;31m:\u001b[0m name 'combined_array1' is not defined\n"
     ]
    }
   ],
   "source": [
    "combined_array1.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d3d2a880-9672-4776-8f15-5e082964c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y2_test, Y2_pred)\n",
    "combined_array2 = np.column_stack((y2_test, Y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9a20a24a-1646-4683-b121-2f67f38e50fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.        , 13.73271561],\n",
       "       [43.        , 41.54024887],\n",
       "       [42.        , 40.99051666],\n",
       "       ...,\n",
       "       [12.        , 11.84365654],\n",
       "       [41.        , 40.63547897],\n",
       "       [12.        , 11.65812302]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e1fa0444-6473-4eaf-b5b2-dd9a1be817fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y3_test, Y3_pred)\n",
    "combined_array3 = np.column_stack((y3_test, Y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ed2327b-b00e-421a-942a-1b49ae21c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8       , 2.25056696],\n",
       "       [9.8       , 9.72095966],\n",
       "       [6.2       , 6.89110184],\n",
       "       ...,\n",
       "       [5.4       , 5.82195044],\n",
       "       [9.4       , 9.263237  ],\n",
       "       [8.8       , 9.11710453]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b8c44e59-cce7-4e33-b5eb-befcb801cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2493402757741605, 0.14454161491909812, 0.1868920259252381)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "def scale_this_point(point_in_space):\n",
    "    X , Y , Z =   point_in_space\n",
    "    X_norm = (X - X_train_df.loc[:,'X'].mean()) / X_train_df.loc[:,'X'].std()\n",
    "    Y_norm = (Y - X_train_df.loc[:,'Y'].mean())/ X_train_df.loc[:,'Y'].std()\n",
    "    Z_norm = (Z - X_train_df.loc[:,'Z'].mean()) / X_train_df.loc[:,'Z'].std()\n",
    "    \n",
    "    return X_norm, Y_norm, Z_norm\n",
    "\n",
    "point = np.array([7.0197861,  3.27338002, 9.94331352])\n",
    "\n",
    "point_in_space_norm = scale_this_point(point)\n",
    "print(point_in_space_norm)\n",
    "point_in_space_norm[0]\n",
    "\n",
    "#prediction on the point\n",
    "NEW_point_to_predict = np.array([[point_in_space_norm[0], point_in_space_norm[1],point_in_space_norm[2]]])\n",
    "Theta1, Theta2, Theta3 = model.predict(NEW_point_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e9db8a4d-5867-44ca-94ce-c1009638f884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.71403]]\n",
      "[[24.71293]]\n",
      "[[26.515377]]\n"
     ]
    }
   ],
   "source": [
    "print(Theta1)\n",
    "print(Theta2)\n",
    "print(Theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65ae7a-0b19-4d66-9b09-4cf9b1d777e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Mój dysk/PYTHON/MACHINE_LEARNING/LINEAR_REGRESSION/INVERSE_KINEMATICS_NEURAL_NETWORK/MODEL/my_model2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
